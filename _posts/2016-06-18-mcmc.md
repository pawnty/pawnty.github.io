---
layout: post
title: 马尔可夫链蒙特卡洛
description: "介绍McMC采样算法"
modified: 2016-06-18
tags: [draft]
categories: [MachineLearning]
---

## 马尔可夫链和平稳分布
周末，笨小孩妈妈出门去，只留笨小孩一个人在家做作业。笨小孩想看电视，但是被妈妈发现后会挨揍。所以，笨小孩每看1分钟电视或做1分钟作业就要随机地决定是继续当前活动还是换到另外一个活动：如果当时正在看电视，继续看电视的概率为$P_{tt}$，换为做作业的概率为$1-P_{tt}$；如果当时在做作业，继续做作业的概率为$P_{hh}$，换为看电视的概率为$1-P_{hh}$。问题来了：笨小孩挨揍的概率是多少？

这个问题里，设笨小孩在第$i$分钟的活动为$X_i$。笨小孩下次活动的概率只与当前的活动有关，只要当前的活动是做作业，不管之前做了多少作业、看了多少电视，下一步做作业的概率都是$P_{hh}$，看电视的概率都是$1-P_{hh}$；只要当前的活动是做作业，不管之前做了多少作业、看了多少电视，下一步做作业的概率都是$P_{hh}$，看电视的概率都是$1-P_{hh}$。这种下一个状态只由当前状态决定的性质$P(X_{i+1}\vert X_0,X_1,\cdots,X_i)=P(X_{i+1}\vert X_i)$，称为马尔可夫性，满足马尔可夫性的随机序列$X_0, X_1, \cdots, X_n$称为马尔可夫链。

笨小孩是否挨揍取决于他妈妈回来时他是否在看电视。设妈妈在第$n$分钟回来，笨小孩挨揍的概率为也就是在$n$分钟看电视的概率$P(X_n=t)$。

在第$i$分钟，笨小孩的活动服从$P(X_i)$，那么在第$i+1$分钟，笨小孩活动的概率为$$P(X_{i+1})=\sum_{X_i\in\{t, h\}}P(X_i)P(X_{i+1}\vert X_i).$$

上式是一个递推公式。只要知道初始状态的概率$P(X_0)$和各个活动间转换的概率，就可以求出第$n$分钟活动的概率$P(X_n)$。

来尝试一下，设$P_{tt}=0.1, P_{hh}=0.3$，计算出笨小孩分别以$1.0, 0.5, 0.3, 0$为初始看电视概率在各个时间挨揍的概率，结果如下图所示。

![enter image description here](http://pawnty.github.io/images/posts/mcmc/figure1.png)

从图中可以看到，不管笨小孩初始看电视的概率为多少，经过一段足够长的时间，笨小孩最后挨揍的概率都一样，并且不再变化，即最初看电视的概率对后面挨揍概率的影响逐渐减小直至完全消失。一段时间后挨揍的概率是否受活动转换概率的影响呢？再设$P_{tt}=0.2, P_{hh}=0.6$，重新绘制结果：

![enter image description here](http://pawnty.github.io/images/posts/mcmc/figure2.png)

一段时间后，不管初始看电视概率为何，笨小孩挨揍的概率又变得一样，只不过这次与上次概率不同。

从这两个结果可以发现一个令人有点惊奇的规律：时间足够长的情况下，计算笨小孩挨揍的概率仅仅需要知道他两个活动间转换的概率，而初始活动的概率甚至确切的时间都可以忽略！

在马尔可夫过程中，最终状态所服从的不再随时间变化的概率分布称为该过程的平稳分布，记为

$$
\pi(X)=\lim_{n\rightarrow \infty}P(X_n).
$$

对于离散状态空间的马尔可夫过程，平稳分布应满足

$$
\pi(X＝j)=\sum_i \pi(X＝i)T_{ij}
$$

$T_{ij}$表示从状态$i$转到状态$j$的概率，矩阵$T=\{T_{ij}\}$称为转移矩阵，满足

$$T_{ij} \ge 0\\
\sum_j T_{ij} = 1.
$$

对于连续状态空间的马尔可夫过程，平稳分布应满足

$$
\pi(x)=\int_{x'} \pi(x')p(x', x)dx'
$$

其中$p(x', x)$叫做马尔可夫核(Markov Kernel)，须满足

$$p(x', x) \ge 0\\
\int_x p(x', x) dx = 1$$

## 马尔可夫链蒙特卡洛

笨小孩挨揍了几次之后，希望将以后挨揍的风险控制为$p$。他应该采取什么偷看电视的策略？

笨小孩最先想到的策略是，将时间分为多个周期，每个周期的前$p$部分做作业，后$1-p$部分看电视。如果妈妈回来的时间在每个周期内是均匀分布的，笨小孩就可以将挨揍的风险控制为$p$。但问题是，他不能保证妈妈回来的时间均匀性，当然他也不敢对妈妈说：“妈妈，你能不能在每个半小时内都均匀随机地选择一个时间回来？"

对笨小孩而言，妈妈回来的时间是不可控的，所以上一种方法不可取。

笨小孩转念一想，之前的随机转换活动等策略不是会产生一个固定的挨揍概率吗？并且只要妈妈回来的时间不是特别早，这个概率就是可靠的。挨揍概率只与活动转换概率有关，只要选择合适的活动转换概率，就可以得到想要的挨揍概率。

根据平稳分布的性质，活动转换的概率需要满足

$$
\pi(X)=\sum_{X'\in \{t,h\}} \pi(X')P(X\vert X')
$$

一个平稳分布不足以确定一个转移矩阵，可以对矩阵加入一些限制。例如细致平衡条件：

$$
P(X)P(X'\vert X)=P(X')P(X\vert X')
$$

满足细致平衡条件一定满足平稳分布的条件，因为

$$
\sum_{X'}P(X')P(X\vert X')=\sum_{X'}P(X)P(X'\vert X)=P(X).
$$

设笨小孩希望将挨揍的风险控制为$0.2$，则满足细致平衡条件要求

$$
0.2 P_{th} = 0.8 P_{ht}
$$

只需要$P_{th}=4P_{ht}$即可，例如$P_{th}=1, P_{ht}=0.25$，


![enter image description here](http://pawnty.github.io/images/posts/mcmc/figure3.png)

或者$P_{th}=0.5, P_{ht}=0.125$,

![enter image description here](http://pawnty.github.io/images/posts/mcmc/figure4.png)

从两张图中可看出，两种活动转换概率下挨揍的概率最终都收敛于$0.2$，不同的是收敛点速度。第一种情况下活动变换的概率要大于第二种情况，因此第一种情况可以在短时间内经历更多次转换，所以可以更快的收敛。不管怎样，笨小孩终于掌握了控制挨揍风险的方法。

仔细分析这一过程可以发现三种概率分布：初始状态分布，状态转移分布会平稳分布。笨小孩做了一件非常了不起的事情，他通过设计状态转移分布得到了想要的平稳分布。这其中的意义是非常远大的，简直撑起了统计推断的半边天！

如果我们需要许多服从概率$p$的样本，而$p$又难以直接采样得出，我们可以采用笨小孩的方法，构建一个转移分布$t$简单易于采样且平稳分布是$p$的马尔可夫过程，在经过足够次采样后就可以得到服从$p$的样本。

具体来说，需要从$p(x)$中采样较困难，可以选择一个简单易于采样的分布$q(x\vert x')$进行采样，根据某种概率$A(x', x)$决定是否转移到新的状态，使细致平衡条件得到满足：

$$
p(x)q(x, x')A(x, x')=p(x')q(x', x)A(x', x)
$$

这里，状态转移的概率分别为$t(x, x')=q(x, x')A(x, x')$和$t(x', x)=q(x', x)A(x', x)$。

为了使平稳分布收敛的更快，我们需要尽可能使状态转换的概率更大些。q(x', x)的选择受可采样性限制，因此只能使$A(x', x)$尽可能大。作为概率，$A(x', x)$最大值为$1$，$A(x, x')$也是。

假设$p(x)q(x, x')>p(x')q(x', x)$，则$A(x, x') < A(x', x)$，令$A(x',x)$取得最大值$1$，可求得$A(x, x')=\frac{p(x')q(x', x)}{p(x)q(x, x')}$;假设$p(x)q(x, x')<p(x')q(x', x)$，则$A(x, x') > A(x', x)$，令$A(x,x')$取得最大值$1$，可求得$A(x', x)=\frac{p(x)q(x, x')}{p(x')q(x', x)}$，综合两种情况，

$$A(x, x')=\min(1, \frac{p(x')q(x', x)}{p(x)q(x, x')}).$$

此种采样算法称为Metropolis–Hastings算法。

> Metropolis–Hastings算法
> 
> 1. 随机设置$X_0$，令$\tau=0$;
> 2. 根据$q(x_{\tau}, x)$采出样本$x'$;
> 3. 从$[0, 1)$上得均匀分布随机采样$u$;
> 4. 如果$u<A(x_{\tau}, x')$,令$X_{\tau+1}=x'$,否则令$X_{\tau_+1}=X_{\tau}$;
> 5. 令$\tau = \tau + 1$;
> 6. 跳至第2步；

Metropolis-Hastings算法得到一系列样本$\{X_{\tau}\}_{\tau=1}^\infty$，相邻的样本之间不是互相独立的，但是可以每隔$M$间隔取一个样本，只要$M$足够大，就可以得到相互独立且分布为$p(x)$的随机变量样本。




